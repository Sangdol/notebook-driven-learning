{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "users = [User(0, \"Hero\"), User(1, \"Dunn\"), User(2, \"Sue\"), User(3, \"Chi\"),\n",
    "         User(4, \"Thor\"), User(5, \"Clive\"), User(6, \"Hicks\"),\n",
    "         User(7, \"Devin\"), User(8, \"Kate\"), User(9, \"Klein\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_pairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "                (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# type alias for keeping track of Friendships\n",
    "Friendships = Dict[int, List[int]]\n",
    "\n",
    "friendships: Friendships = {user.id: [] for user in users}\n",
    "\n",
    "for i, j in friend_pairs:\n",
    "    friendships[i].append(j)\n",
    "    friendships[j].append(i)\n",
    "\n",
    "assert friendships[4] == [3, 5]\n",
    "assert friendships[8] == [6, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "Path = List[int]\n",
    "\n",
    "def shortest_paths_from(from_user_id: int,\n",
    "                        friendships: Friendships) -> Dict[int, List[Path]]:\n",
    "    # A dictionary from user_id to *all* shortest paths to that user.\n",
    "    shortest_paths_to: Dict[int, List[Path]] = {from_user_id: [[]]}\n",
    "\n",
    "    # A queue of (previous user, next user) that we need to check.\n",
    "    # Starts out with all pairs (from_user, friend_of_from_user).\n",
    "    frontier = deque((from_user_id, friend_id)\n",
    "                     for friend_id in friendships[from_user_id])\n",
    "\n",
    "    # Keep going until we empty the queue.\n",
    "    while frontier:\n",
    "        # Remove the pair that's next in the queue.\n",
    "        prev_user_id, user_id = frontier.popleft()\n",
    "\n",
    "        # Because of the way we're adding to the queue,\n",
    "        # necessarily we already know some shortest paths to prev_user.\n",
    "        paths_to_prev_user = shortest_paths_to[prev_user_id]\n",
    "        new_paths_to_user = [path + [user_id] for path in paths_to_prev_user]\n",
    "\n",
    "        # It's possible we already know a shortest path to user_id.\n",
    "        old_paths_to_user = shortest_paths_to.get(user_id, [])\n",
    "\n",
    "        # What's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_user:\n",
    "            min_path_length = len(old_paths_to_user[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "\n",
    "        # Only keep paths that aren't too long and are actually new.\n",
    "        new_paths_to_user = [path\n",
    "                             for path in new_paths_to_user\n",
    "                             if len(path) <= min_path_length\n",
    "                             and path not in old_paths_to_user]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_user + new_paths_to_user\n",
    "\n",
    "        # Add never-seen neighbors to the frontier.\n",
    "        frontier.extend((user_id, friend_id)\n",
    "                        for friend_id in friendships[user_id]\n",
    "                        if friend_id not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each from_user, for each to_user, a list of shortest paths.\n",
    "shortest_paths = {user.id: shortest_paths_from(user.id, friendships)\n",
    "                  for user in users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality = {user.id: 0.0 for user in users}\n",
    "\n",
    "for source in users:\n",
    "    for target_id, paths in shortest_paths[source.id].items():\n",
    "        if source.id < target_id:      # don't double count\n",
    "            num_paths = len(paths)     # how many shortest paths?\n",
    "            contrib = 1 / num_paths    # contribution to centrality\n",
    "            for path in paths:\n",
    "                for between_id in path:\n",
    "                    if between_id not in [source.id, target_id]:\n",
    "                        betweenness_centrality[between_id] += contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farness(user_id: int) -> float:\n",
    "    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n",
    "    return sum(len(paths[0])\n",
    "               for paths in shortest_paths[user_id].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_centrality = {user.id: 1 / farness(user.id) for user in users}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Matrix, make_matrix, shape\n",
    "\n",
    "def matrix_times_matrix(m1: Matrix, m2: Matrix) -> Matrix:\n",
    "    nr1, nc1 = shape(m1)\n",
    "    nr2, nc2 = shape(m2)\n",
    "    assert nc1 == nr2, \"must have (# of columns in m1) == (# of rows in m2)\"\n",
    "\n",
    "    def entry_fn(i: int, j: int) -> float:\n",
    "        \"\"\"dot product of i-th row of m1 with j-th column of m2\"\"\"\n",
    "        return sum(m1[i][k] * m2[k][j] for k in range(nc1))\n",
    "\n",
    "    return make_matrix(nr1, nc2, entry_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Vector, dot\n",
    "\n",
    "def matrix_times_vector(m: Matrix, v: Vector) -> Vector:\n",
    "    nr, nc = shape(m)\n",
    "    n = len(v)\n",
    "    assert nc == n, \"must have (# of cols in m) == (# of elements in v)\"\n",
    "\n",
    "    return [dot(row, v) for row in m]  # output has length nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "from scratch.linear_algebra import magnitude, distance\n",
    "\n",
    "def find_eigenvector(m: Matrix,\n",
    "                     tolerance: float = 0.00001) -> Tuple[Vector, float]:\n",
    "    guess = [random.random() for _ in m]\n",
    "\n",
    "    while True:\n",
    "        result = matrix_times_vector(m, guess)    # transform guess\n",
    "        norm = magnitude(result)                  # compute norm\n",
    "        next_guess = [x / norm for x in result]   # rescale\n",
    "\n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            # convergence so return (eigenvector, eigenvalue)\n",
    "            return next_guess, norm\n",
    "\n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random\n",
    "from scratch.linear_algebra import magnitude, distance\n",
    "\n",
    "def find_eigenvector(m: Matrix,\n",
    "                     tolerance: float = 0.00001) -> Tuple[Vector, float]:\n",
    "    guess = [random.random() for _ in m]\n",
    "\n",
    "    while True:\n",
    "        result = matrix_times_vector(m, guess)    # transform guess\n",
    "        norm = magnitude(result)                  # compute norm\n",
    "        next_guess = [x / norm for x in result]   # rescale\n",
    "\n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            # convergence so return (eigenvector, eigenvalue)\n",
    "            return next_guess, norm\n",
    "\n",
    "        guess = next_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no eigenvector for this\n",
    "rotate = [[ 0, 1],\n",
    "          [-1, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entry_fn(i: int, j: int):\n",
    "    return 1 if (i, j) in friend_pairs or (j, i) in friend_pairs else 0\n",
    "\n",
    "n = len(users)\n",
    "adjacency_matrix = make_matrix(n, n, entry_fn)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38578009535518015,\n",
       " 0.514790260696577,\n",
       " 0.514790260696577,\n",
       " 0.4733122188164715,\n",
       " 0.23361025338162345,\n",
       " 0.15014572998309983,\n",
       " 0.08355551312646471,\n",
       " 0.08355551312646471,\n",
       " 0.072840253079769,\n",
       " 0.027294611136895703]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)\n",
    "eigenvector_centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.029580521393154,\n",
       " 1.3738825748682286,\n",
       " 1.3738825748682286,\n",
       " 1.2631907747747775,\n",
       " 0.6234579487995713,\n",
       " 0.40072127963455284,\n",
       " 0.22298598306286882,\n",
       " 0.22298598306286882,\n",
       " 0.19440563738982514,\n",
       " 0.072840253079769]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtv = matrix_times_vector(adjacency_matrix, eigenvector_centralities)\n",
    "mtv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.66882748, 2.66882006, 2.66882006, 2.66883196, 2.66879531,\n",
       "       2.66888229, 2.66871658, 2.66871658, 2.66893138, 2.66866792])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(mtv) / eigenvector_centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 1], [1, 0, 1, 1], [0, 1, 0, 0], [1, 1, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5227196422623628,\n",
       " 0.6116311454238872,\n",
       " 0.2818433840523654,\n",
       " 0.5227196422619702]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small example\n",
    "users2 = [User(0, \"Hero\"), User(1, \"Dunn\"), User(2, \"Sue\"), User(3, \"Sue2\")]\n",
    "friend_pairs2 = [(0, 1), (1, 2), (1, 3), (0, 3)]\n",
    "n = len(users2)\n",
    "\n",
    "def entry_fn2(i: int, j: int):\n",
    "    return 1 if (i, j) in friend_pairs2 or (j, i) in friend_pairs2 else 0\n",
    "\n",
    "adjacency_matrix = make_matrix(n, n, entry_fn2)\n",
    "print(adjacency_matrix)\n",
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)\n",
    "eigenvector_centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Graphs and PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2),\n",
    "                (2, 1), (1, 3), (2, 3), (3, 4), (5, 4),\n",
    "                (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2, 0: 2, 2: 2, 3: 2, 4: 2, 6: 1, 5: 1, 8: 1, 7: 1, 9: 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "endorsement_counts = Counter(target for source, target in endorsements)\n",
    "endorsement_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def page_rank(users: List[User],\n",
    "              endorsements: List[Tuple[int, int]],\n",
    "              damping: float = 0.85,\n",
    "              num_iters: int = 100) -> Dict[int, float]:\n",
    "    # Compute how many people each person endorses\n",
    "    outgoing_counts = Counter(target for source, target in endorsements)\n",
    "\n",
    "    # Initially distribute PageRank evenly\n",
    "    num_users = len(users)\n",
    "    pr = {user.id : 1 / num_users for user in users}\n",
    "\n",
    "    # Small fraction of PageRank that each node gets each iteration\n",
    "    base_pr = (1 - damping) / num_users\n",
    "\n",
    "    for iter in tqdm.trange(num_iters):\n",
    "        next_pr = {user.id : base_pr for user in users}  # start with base_pr\n",
    "\n",
    "        for source, target in endorsements:\n",
    "            # Add damped fraction of source pr to target\n",
    "            next_pr[target] += damping * pr[source] / outgoing_counts[source]\n",
    "\n",
    "        pr = next_pr\n",
    "\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 103079.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.1,\n",
       " 1: 0.1,\n",
       " 2: 0.1,\n",
       " 3: 0.1,\n",
       " 4: 0.14250000000000002,\n",
       " 5: 0.1,\n",
       " 6: 0.1,\n",
       " 7: 0.1,\n",
       " 8: 0.1,\n",
       " 9: 0.1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = page_rank(users, endorsements)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
